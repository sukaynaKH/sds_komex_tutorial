{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align: center;\" >\n",
    "<h1 style=\"margin-top: 0.2em; margin-bottom: 0.1em;\">Assignment 3</h1>\n",
    "</div>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Install requirements. \n",
    "\n",
    "The following cell contains all the necessary dependencies needed for this task. If you run the cell everything will be installed. \n",
    "\n",
    "\n",
    "* [`transformers`](https://huggingface.co/) is a Python package for creating and working with transformers. [Here](https://huggingface.co/docs) is the documentation of `transformers`.\n",
    "* [`pandas`](https://pandas.pydata.org/docs/index.html) is a Python package for creating and working with tabular data. [Here](https://pandas.pydata.org/docs/reference/index.html) is the documentation of `pandas`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Looking in indexes: https://pypi.org/simple, https://packagecloud.io/github/git-lfs/pypi/simple\n",
      "Requirement already satisfied: transformers in /home/sukayna/.local/lib/python3.10/site-packages (4.38.1)\n",
      "Requirement already satisfied: filelock in /home/sukayna/.local/lib/python3.10/site-packages (from transformers) (3.13.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /home/sukayna/.local/lib/python3.10/site-packages (from transformers) (0.21.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/sukayna/.local/lib/python3.10/site-packages (from transformers) (1.24.1)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/sukayna/.local/lib/python3.10/site-packages (from transformers) (23.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/lib/python3/dist-packages (from transformers) (5.4.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/sukayna/.local/lib/python3.10/site-packages (from transformers) (2023.10.3)\n",
      "Requirement already satisfied: requests in /home/sukayna/.local/lib/python3.10/site-packages (from transformers) (2.31.0)\n",
      "Requirement already satisfied: tokenizers<0.19,>=0.14 in /home/sukayna/.local/lib/python3.10/site-packages (from transformers) (0.15.2)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /home/sukayna/.local/lib/python3.10/site-packages (from transformers) (0.4.2)\n",
      "Requirement already satisfied: tqdm>=4.27 in /home/sukayna/.local/lib/python3.10/site-packages (from transformers) (4.66.2)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /home/sukayna/.local/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (2023.10.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/sukayna/.local/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (4.10.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/lib/python3/dist-packages (from requests->transformers) (2.0.6)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/lib/python3/dist-packages (from requests->transformers) (3.3)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/sukayna/.local/lib/python3.10/site-packages (from requests->transformers) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/sukayna/.local/lib/python3.10/site-packages (from requests->transformers) (2023.7.22)\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Looking in indexes: https://pypi.org/simple, https://packagecloud.io/github/git-lfs/pypi/simple\n",
      "Requirement already satisfied: pandas in /home/sukayna/.local/lib/python3.10/site-packages (2.0.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/sukayna/.local/lib/python3.10/site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/lib/python3/dist-packages (from pandas) (2022.1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /home/sukayna/.local/lib/python3.10/site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: numpy>=1.21.0 in /home/sukayna/.local/lib/python3.10/site-packages (from pandas) (1.24.1)\n",
      "Requirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "! pip install transformers\n",
    "! pip install pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You may need to restart the Kernel after installing the dependencies!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import requirements\n",
    "The cell below imports all necessary dependancies. Make sure they are installed (see cell above)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from transformers import pipeline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the following exercise you will use the emotion classification model [LEIA](https://huggingface.co/LEIA/LEIA-base) to classify the emotion of the sentences in the [enISEAR dataset](https://www.romanklinger.de/data-sets/). You read more about the `LEIA-base` in the [documentation](https://huggingface.co/LEIA/LEIA-base) and learn about the implementation details from this [paper](https://arxiv.org/abs/2304.10973)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.1 LEIA introduction\n",
    "* Load the `LEIA-base` model and tokenize either as a [pipeline](https://huggingface.co/docs/transformers/main_classes/pipelines), or you can load the model and the tokenizer [directly](https://huggingface.co/docs/transformers/autoclass_tutorial) and implement the classification steps by yourself. LEIA only accepts sentences with up to 128 tokens. Make sure that your tokenizer [truncates](https://huggingface.co/docs/transformers/pad_truncation) longer sentences to this lenght to avoid errors.\n",
    "* What are the possible labels the model can predict?\n",
    "* Input the sentence `Today is a great day.` to the model, and predict the emotion of the sentence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Looking in indexes: https://pypi.org/simple, https://packagecloud.io/github/git-lfs/pypi/simple\n",
      "Requirement already satisfied: ipywidgets in /usr/lib/python3/dist-packages (6.0.0)\n",
      "Collecting ipywidgets\n",
      "  Using cached ipywidgets-8.1.2-py3-none-any.whl.metadata (2.4 kB)\n",
      "Requirement already satisfied: comm>=0.1.3 in /home/sukayna/.local/lib/python3.10/site-packages (from ipywidgets) (0.2.1)\n",
      "Requirement already satisfied: ipython>=6.1.0 in /usr/lib/python3/dist-packages (from ipywidgets) (7.31.1)\n",
      "Requirement already satisfied: traitlets>=4.3.1 in /home/sukayna/.local/lib/python3.10/site-packages (from ipywidgets) (5.14.1)\n",
      "Collecting widgetsnbextension~=4.0.10 (from ipywidgets)\n",
      "  Using cached widgetsnbextension-4.0.10-py3-none-any.whl.metadata (1.6 kB)\n",
      "Collecting jupyterlab-widgets~=3.0.10 (from ipywidgets)\n",
      "  Using cached jupyterlab_widgets-3.0.10-py3-none-any.whl.metadata (4.1 kB)\n",
      "Using cached ipywidgets-8.1.2-py3-none-any.whl (139 kB)\n",
      "Using cached jupyterlab_widgets-3.0.10-py3-none-any.whl (215 kB)\n",
      "Using cached widgetsnbextension-4.0.10-py3-none-any.whl (2.3 MB)\n",
      "Installing collected packages: widgetsnbextension, jupyterlab-widgets, ipywidgets\n",
      "Successfully installed ipywidgets-8.1.2 jupyterlab-widgets-3.0.10 widgetsnbextension-4.0.10\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade ipywidgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e4a993ffa45481d9d29852fd623e2e1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/540M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sukayna/.local/lib/python3.10/site-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  return self.fget.__get__(instance, owner)()\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5c5a1bb0f349469585a8e65a5a69ff26",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/473 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bdf2110eb36644999b528dd6671d6ca2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/843k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e25a6c2e14624963a74ebf031352d60e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "bpe.codes:   0%|          | 0.00/1.08M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "66d92724cc1b4853a1f582ce9daf4deb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "added_tokens.json:   0%|          | 0.00/22.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0470ef014f844360bafb581f75a3bea7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/167 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# import pipeline\n",
    "pipe_leia = pipeline('text-classification', model=\"LEIA/LEIA-base\", tokenizer=\"LEIA/LEIA-base\", truncation=True, max_length=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pipe_leia(\"Today is a great day\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Happiness'"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results[0]['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'Sadness', 1: 'Affection', 2: 'Fear', 3: 'Happiness', 4: 'Anger'}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe_leia.model.config.id2label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2 enISEAR dataset\n",
    "* Load the enISEAR dataset.\n",
    "* What are the possible labels in the dataset? (the `Prior_Emotion` column stores the actual label)\n",
    "* The last 7 columns store the labels given by the annotators. Create a new column `Annotator_Majority_Label`, which stores the emotion with the highest annotator score (i.e. the emotion the highest number of annotators chose for the given sentence).\n",
    "* What percent of the sentences were correctly classified by the (majority vote of the) annotators?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"enISEAR.tsv\", sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Sentence_id', 'Prior_Emotion', 'Sentence', 'Temporal_Distance',\n",
       "       'Intensity', 'Duration', 'Gender', 'City', 'Country', 'Worker_id',\n",
       "       'Time', 'Anger', 'Disgust', 'Fear', 'Guilt', 'Joy', 'Sadness', 'Shame'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Fear', 'Shame', 'Guilt', ..., 'Shame', 'Shame', 'Shame'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.Prior_Emotion.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Annotator_Majority_Label'] = data.iloc[:,-7:].idxmax(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    Sadness\n",
       "1      Guilt\n",
       "Name: Annotator_Majority_Label, dtype: object"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['Annotator_Majority_Label'].head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.3 Classification\n",
    "* Drop the rows from the enISEAR dataset, where the `Prior_Emotion` is not one of `Fear`, `Sadness`, `Anger` or `Joy`\n",
    "* Use `Leia` to classify the emotion of each remaining sentence in the dataset, and add a column `Leia_Label` to store the predicted classes\n",
    "* Now remove `I felt ... ` from the beginning of each sentence, and rerun the classfication. Store your results in a column named `Leia_Label_Clean`\n",
    "* Where the model predicted `Happiness` or `Affection`, change the prediction to `Joy` to match the dataset's labels (for both columns -> `Leia_Label` and `Leia_Label_Clean`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "429"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "drop_emotions = ['Fear', 'Sadness', 'Anger', 'Joy']\n",
    "data = data[~data.Prior_Emotion.isin(drop_emotions)]\n",
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence_id</th>\n",
       "      <th>Prior_Emotion</th>\n",
       "      <th>Sentence</th>\n",
       "      <th>Temporal_Distance</th>\n",
       "      <th>Intensity</th>\n",
       "      <th>Duration</th>\n",
       "      <th>Gender</th>\n",
       "      <th>City</th>\n",
       "      <th>Country</th>\n",
       "      <th>Worker_id</th>\n",
       "      <th>Time</th>\n",
       "      <th>Anger</th>\n",
       "      <th>Disgust</th>\n",
       "      <th>Fear</th>\n",
       "      <th>Guilt</th>\n",
       "      <th>Joy</th>\n",
       "      <th>Sadness</th>\n",
       "      <th>Shame</th>\n",
       "      <th>Annotator_Majority_Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>597</td>\n",
       "      <td>Shame</td>\n",
       "      <td>I felt ... one Christmas as one of our patient...</td>\n",
       "      <td>Y</td>\n",
       "      <td>I</td>\n",
       "      <td>Dom</td>\n",
       "      <td>Fl</td>\n",
       "      <td>Dulwich</td>\n",
       "      <td>GBR</td>\n",
       "      <td>86</td>\n",
       "      <td>11/26/2018 06:52:02</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Guilt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>282</td>\n",
       "      <td>Guilt</td>\n",
       "      <td>I felt ... because I could not help a friend w...</td>\n",
       "      <td>M</td>\n",
       "      <td>Mi</td>\n",
       "      <td>Dom</td>\n",
       "      <td>Fl</td>\n",
       "      <td>Linlithgow</td>\n",
       "      <td>GBR</td>\n",
       "      <td>83</td>\n",
       "      <td>11/21/2018 18:45:00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Guilt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>171</td>\n",
       "      <td>Disgust</td>\n",
       "      <td>I felt ... when I read that hunters had killed...</td>\n",
       "      <td>Y</td>\n",
       "      <td>Mi</td>\n",
       "      <td>H</td>\n",
       "      <td>Ml</td>\n",
       "      <td>Bristol</td>\n",
       "      <td>GBR</td>\n",
       "      <td>87</td>\n",
       "      <td>11/28/2018 00:55:11</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>Anger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>181</td>\n",
       "      <td>Disgust</td>\n",
       "      <td>I felt ... when I stepped in dog shit on the w...</td>\n",
       "      <td>M</td>\n",
       "      <td>I</td>\n",
       "      <td>H</td>\n",
       "      <td>Fl</td>\n",
       "      <td>Shepherds Bush</td>\n",
       "      <td>GBR</td>\n",
       "      <td>90</td>\n",
       "      <td>11/28/2018 21:42:00</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Disgust</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>642</td>\n",
       "      <td>Shame</td>\n",
       "      <td>I felt ... when my daughter was rude to my wife.</td>\n",
       "      <td>D</td>\n",
       "      <td>N</td>\n",
       "      <td>Fm</td>\n",
       "      <td>Ml</td>\n",
       "      <td>Chelmsford</td>\n",
       "      <td>GBR</td>\n",
       "      <td>91</td>\n",
       "      <td>11/26/2018 23:35:24</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>Anger</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Sentence_id Prior_Emotion  \\\n",
       "1          597         Shame   \n",
       "2          282         Guilt   \n",
       "3          171       Disgust   \n",
       "5          181       Disgust   \n",
       "7          642         Shame   \n",
       "\n",
       "                                            Sentence Temporal_Distance  \\\n",
       "1  I felt ... one Christmas as one of our patient...                 Y   \n",
       "2  I felt ... because I could not help a friend w...                 M   \n",
       "3  I felt ... when I read that hunters had killed...                 Y   \n",
       "5  I felt ... when I stepped in dog shit on the w...                 M   \n",
       "7   I felt ... when my daughter was rude to my wife.                 D   \n",
       "\n",
       "  Intensity Duration Gender            City Country  Worker_id  \\\n",
       "1         I      Dom     Fl         Dulwich     GBR         86   \n",
       "2        Mi      Dom     Fl      Linlithgow     GBR         83   \n",
       "3        Mi        H     Ml         Bristol     GBR         87   \n",
       "5         I        H     Fl  Shepherds Bush     GBR         90   \n",
       "7         N       Fm     Ml      Chelmsford     GBR         91   \n",
       "\n",
       "                  Time  Anger  Disgust  Fear  Guilt  Joy  Sadness  Shame  \\\n",
       "1  11/26/2018 06:52:02      1        0     0      4    0        0      0   \n",
       "2  11/21/2018 18:45:00      0        0     0      4    0        1      0   \n",
       "3  11/28/2018 00:55:11      3        0     0      0    0        2      0   \n",
       "5  11/28/2018 21:42:00      0        5     0      0    0        0      0   \n",
       "7  11/26/2018 23:35:24      3        0     0      0    0        2      0   \n",
       "\n",
       "  Annotator_Majority_Label  \n",
       "1                    Guilt  \n",
       "2                    Guilt  \n",
       "3                    Anger  \n",
       "5                  Disgust  \n",
       "7                    Anger  "
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data = data.drop(['Leia_Label'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = [pipe_leia(sent) for sent in data['Sentence']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Leia_Label'] = [d[\"label\"] for row in results for d in row]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Sentence'] = data['Sentence'].str.replace('^I felt ', '', regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Leia_Label_Clean'] = [d[\"label\"] for row in [pipe_leia(sent) for sent in data['Sentence']] for d in row]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[['Leia_Label', 'Leia_Label_Clean']] = data[['Leia_Label', 'Leia_Label_Clean']].replace({'Happiness': 'Joy', 'Affection': 'Joy'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['Fear', 'Anger'],\n",
       "       ['Joy', 'Joy'],\n",
       "       ['Joy', 'Joy']], dtype=object)"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[['Leia_Label', 'Leia_Label_Clean']].values[6:9]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.4 Evaluate Performance\n",
    "\n",
    "First, let's calculate the accuracy for the two classifiers, plot the results. Hint: You can do bar plots to compare the values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next calculate the precision of the `\"Joy\"` class for the data.\n",
    "This is calculated as follows:\n",
    "$\n",
    "\\begin{align}\n",
    "    precision = \\frac{TP}{TP + FP}\n",
    "\\end{align}\n",
    "$\n",
    "*Note: Here the Positive samples are the one with the the class `\"Joy\"`*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now calculate the recall score. This is done by:\n",
    "$\n",
    "\\begin{align}\n",
    "    recall = \\frac{TP}{TP + FN}\n",
    "\\end{align}\n",
    "$\n",
    "*Note: Here the Positive samples are the one with the the class `\"Joy\"`*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Last, calculate the [F1 score](https://towardsdatascience.com/the-f1-score-bec2bbc38aa6) of the joy class. The F1 score is calculated as:\n",
    "\n",
    "$\n",
    "\\begin{align}\n",
    "    F_1 = 2 * \\frac{precision * recall}{precision + recall}\n",
    "\\end{align}\n",
    "$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This can also be done for the other classes `'Sadness', 'Guilt', 'Anger', 'Disgust', 'Fear', 'Joy', 'Shame'`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, try to calculate the mean f1 score over all classes for each of the classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.5 Interpretation\n",
    "\n",
    "* Discuss your results. \n",
    "* Are the models accurately predicting human emotions?\n",
    "* Which approach seems to work better? Why?\n",
    "* What kind of additional preprocessing could we perform to improve the model's predictions?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1 Data annotation\n",
    "* In the following exercise you will need to test emotion detection methods on data from [Vent](https://www.vent.co/), a website where users talk about their feelings. \n",
    "* On GitHub, in your `a03` folder you can find 3 files. First open `sample_for_labeling.csv`, and label each row according the emotion the sentence expresses. The possible classes are: 0 (Sadness), 1 (Affection), 2 (Fear), 3 (Happiness), 4 (Anger). ***Important: Make sure to upload the labeled data with your submission.***\n",
    "* After you finished labeling the data load it as a pandas dataframe. Also load `sample_with_labels.csv` as a dataframe, which contains the actual labels of the data.\n",
    "* Merge the two dataframes, and rename the column containing your labels as `label_human`.\n",
    "* Rename the class ids (0, 1, 2, ...) stored in the `label`, and `label_human` columns to the class names (Sadness, Affection, ...)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2 LEIA\n",
    "* Use the [LEIA](https://huggingface.co/LEIA/LEIA-base) model introduced in the previous exercise to classify the sentences and store the results in a column named `label_leia`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3 Analysis\n",
    "* Look at the performance of the the model, as well as the quality of your annotation using the metrics introduced in part 1 (accuracy, precision, recall) or other metrics you find interesting. Create informative visualizations to aid the comparison.\n",
    "* Discuss your results. \n",
    "* Are the models accurately predicting human emotions?\n",
    "* Which approach seems to work better? Why?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "46e2835a142a16ae115bce5fddf19f27ce13b17a4ab8ded638c88ab5ce5171d2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
